{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "675d4d48-c7b4-4d32-9c47-7f1b0188b319",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import string\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import BertTokenizer, BertModel, AutoModel, AutoTokenizer\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f766f82-ef12-4cbc-8ff3-d5e1f3e96066",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37c96ecc-b4f2-4e12-8241-7bec01a3b303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['business', 'entertainment', 'politics', 'sport', 'tech']\n"
     ]
    }
   ],
   "source": [
    "# Get the data directory\n",
    "data_dir = os.path.join(os.getcwd(), \"scenario_c_data\")\n",
    "\n",
    "# List all directories in the current directory\n",
    "topics = [d for d in os.listdir(data_dir) \n",
    "                   if os.path.isdir(os.path.join(data_dir, d)) and d != '.ipynb_checkpoints'\n",
    "              ]\n",
    "\n",
    "print(topics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79185962-0bef-4f2e-a4ca-01fd0c85a911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary mapping each topic to its subdirectories\n",
    "text_dir_dict = {\n",
    "    topic: [d for d in os.listdir(os.path.join(data_dir, topic))]\n",
    "    for topic in topics\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d75e29c-ee64-4630-a19d-f85b2ffc2c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "business: 510\n",
      "entertainment: 386\n",
      "politics: 417\n",
      "sport: 511\n",
      "tech: 401\n"
     ]
    }
   ],
   "source": [
    "text_dict = {}\n",
    "\n",
    "for topic in topics:\n",
    "    # Initialize a dictionary to store file contents for each topic\n",
    "    text_dict[topic] = []\n",
    "    \n",
    "    for filename in text_dir_dict[topic]:\n",
    "        # Construct the full file path using os.path.join\n",
    "        file_path = os.path.join(data_dir, topic, filename)\n",
    "        \n",
    "        # Check if it's a directory (e.g., '.ipynb_checkpoints') and skip it\n",
    "        if os.path.isdir(file_path):\n",
    "            continue\n",
    "            \n",
    "        # Open the file and read its content as a string\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "            \n",
    "        text_dict[topic].append(content)\n",
    "        \n",
    "for topic in text_dict:\n",
    "    print(f\"{topic}: {len(text_dict[topic])}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e429297-c670-496f-9e20-16032279fbd0",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57fc4a35-f162-4b0c-9386-aa134c92229b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function to clean text\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove unnecessary characters (basic cleaning)\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http[s]?://\\S+|www\\.\\S+', '', text)  # Removes URLs\n",
    "    \n",
    "    # Remove hashtags\n",
    "    text = re.sub(r'#\\S+', '', text)  # Removes hashtags\n",
    "    \n",
    "    # Remove punctuation and special characters\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    \n",
    "    # Remove extra spaces (including leading and trailing whitespace)\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ccfea34-0bdf-4a08-893f-2a2222a119a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the articles in text_dict\n",
    "for topic in text_dict:\n",
    "    text_dict[topic] = [preprocess_text(article) for article in text_dict[topic]]\n",
    "    \n",
    "# Create a flat list of all articles across topics\n",
    "all_articles = []\n",
    "article_labels = []\n",
    "\n",
    "for topic in text_dict:\n",
    "    for article in text_dict[topic]:\n",
    "        all_articles.append(article)\n",
    "        article_labels.append(topic)  # Keep track of which topic each article belongs to\n",
    "\n",
    "unique_articles = []\n",
    "seen_articles = set()\n",
    "\n",
    "for article, label in zip(all_articles, article_labels):\n",
    "    if article not in seen_articles:  # Check if the article is a duplicate\n",
    "        unique_articles.append(article)\n",
    "        seen_articles.add(article)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd347a3-125d-4cac-bf29-b8973e8ca667",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e68207f-c553-44b5-8db8-5b3ff416f5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "\n",
    "def get_tfidf(text):\n",
    "    return tfidf_vectorizer.transform([preprocess_text(text)])\n",
    "    \n",
    "# Fit and transform all articles to get their TF-IDF matrix\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(unique_articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb42efc-1fb5-4d01-9079-59c9a6e3943f",
   "metadata": {},
   "source": [
    "## bert-base-uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc4e07e2-7918-46cf-bd9d-e1e53b2dd806",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding articles: 100%|██████████| 2122/2122 [11:02<00:00,  3.20article/s]\n"
     ]
    }
   ],
   "source": [
    "# Load BERT model and tokenizer\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Function to get BERT embeddings\n",
    "def get_bert(text):\n",
    "    inputs = bert_tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(**inputs)\n",
    "        \n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "    \n",
    "# Encode all articles using BERT with progress tracking\n",
    "bert_embeddings = np.array([get_bert(article) for article in tqdm(unique_articles, desc=\"Encoding articles\", unit=\"article\")])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451abc06-917c-435c-b82e-ed8d0bbe48ba",
   "metadata": {},
   "source": [
    "## gte-base-en-v1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac38df0b-6742-4b92-abe4-a8e3560f73eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#NOTE: Requires transformers>=4.36.0\n",
    "\n",
    "# Load GTE model and tokenizer\n",
    "gte_tokenizer = AutoTokenizer.from_pretrained('Alibaba-NLP/gte-base-en-v1.5')\n",
    "gte_model = AutoModel.from_pretrained('Alibaba-NLP/gte-base-en-v1.5', trust_remote_code=True)\n",
    "\n",
    "# Function to get GTE embeddings\n",
    "def get_gte(text):\n",
    "    inputs = gte_tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=8192)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = gte_model(**inputs)\n",
    "        \n",
    "    # Use the mean of last_hidden_state across tokens for embedding\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1).squeeze()\n",
    "    \n",
    "    # Optionally normalize embeddings\n",
    "    return F.normalize(embeddings, p=2, dim=0).numpy()\n",
    "\n",
    "# Encode all articles using GTE with progress tracking\n",
    "gte_embeddings = np.array([get_gte(article) for article in unique_articles])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742b9f23-3741-4eee-80fd-2c329455ef10",
   "metadata": {},
   "source": [
    "## bge-large-zh-v1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28bfff74-02c5-41ee-8669-60cc47ada549",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\torch\\_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "# Load the Sentence Transformer model\n",
    "bge_model = SentenceTransformer('BAAI/bge-large-zh-v1.5')\n",
    "\n",
    "def get_bge(text_list):\n",
    "    return bge_model.encode(text_list, normalize_embeddings=True)\n",
    "\n",
    "bge_embeddings = get_bge(unique_articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32760864-3691-4774-b401-5743d061edf7",
   "metadata": {},
   "source": [
    "## e5-base-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c29bf70e-6445-409f-8ee9-fd9590ce55a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at alloc_cpu.cpp:80] data. DefaultCPUAllocator: not enough memory: you tried to allocate 26700939264 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 36\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;66;03m# Normalize embeddings\u001b[39;00m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mnormalize(embeddings, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 36\u001b[0m e5_embeddings \u001b[38;5;241m=\u001b[39m get_e5(unique_articles)\n",
      "Cell \u001b[1;32mIn[12], line 28\u001b[0m, in \u001b[0;36mget_e5\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     25\u001b[0m inputs \u001b[38;5;241m=\u001b[39m e5_tokenizer(text, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 28\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m e5_model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Apply average pooling\u001b[39;00m\n\u001b[0;32m     31\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m average_pool(outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state, inputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1013\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1004\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m   1006\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[0;32m   1007\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   1008\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1011\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[0;32m   1012\u001b[0m )\n\u001b[1;32m-> 1013\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[0;32m   1014\u001b[0m     embedding_output,\n\u001b[0;32m   1015\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mextended_attention_mask,\n\u001b[0;32m   1016\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[0;32m   1017\u001b[0m     encoder_hidden_states\u001b[38;5;241m=\u001b[39mencoder_hidden_states,\n\u001b[0;32m   1018\u001b[0m     encoder_attention_mask\u001b[38;5;241m=\u001b[39mencoder_extended_attention_mask,\n\u001b[0;32m   1019\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[0;32m   1020\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[0;32m   1021\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m   1022\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m   1023\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m   1024\u001b[0m )\n\u001b[0;32m   1025\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1026\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:607\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    596\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    597\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    598\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    604\u001b[0m         output_attentions,\n\u001b[0;32m    605\u001b[0m     )\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 607\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m layer_module(\n\u001b[0;32m    608\u001b[0m         hidden_states,\n\u001b[0;32m    609\u001b[0m         attention_mask,\n\u001b[0;32m    610\u001b[0m         layer_head_mask,\n\u001b[0;32m    611\u001b[0m         encoder_hidden_states,\n\u001b[0;32m    612\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    613\u001b[0m         past_key_value,\n\u001b[0;32m    614\u001b[0m         output_attentions,\n\u001b[0;32m    615\u001b[0m     )\n\u001b[0;32m    617\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:497\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    486\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    487\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    494\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m    495\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[0;32m    496\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 497\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention(\n\u001b[0;32m    498\u001b[0m         hidden_states,\n\u001b[0;32m    499\u001b[0m         attention_mask,\n\u001b[0;32m    500\u001b[0m         head_mask,\n\u001b[0;32m    501\u001b[0m         output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m    502\u001b[0m         past_key_value\u001b[38;5;241m=\u001b[39mself_attn_past_key_value,\n\u001b[0;32m    503\u001b[0m     )\n\u001b[0;32m    504\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    506\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:427\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    419\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    425\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    426\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m--> 427\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself(\n\u001b[0;32m    428\u001b[0m         hidden_states,\n\u001b[0;32m    429\u001b[0m         attention_mask,\n\u001b[0;32m    430\u001b[0m         head_mask,\n\u001b[0;32m    431\u001b[0m         encoder_hidden_states,\n\u001b[0;32m    432\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    433\u001b[0m         past_key_value,\n\u001b[0;32m    434\u001b[0m         output_attentions,\n\u001b[0;32m    435\u001b[0m     )\n\u001b[0;32m    436\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[0;32m    437\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:325\u001b[0m, in \u001b[0;36mBertSelfAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    322\u001b[0m     past_key_value \u001b[38;5;241m=\u001b[39m (key_layer, value_layer)\n\u001b[0;32m    324\u001b[0m \u001b[38;5;66;03m# Take the dot product between \"query\" and \"key\" to get the raw attention scores.\u001b[39;00m\n\u001b[1;32m--> 325\u001b[0m attention_scores \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(query_layer, key_layer\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_embedding_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelative_key\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_embedding_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelative_key_query\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    328\u001b[0m     query_length, key_length \u001b[38;5;241m=\u001b[39m query_layer\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m], key_layer\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at alloc_cpu.cpp:80] data. DefaultCPUAllocator: not enough memory: you tried to allocate 26700939264 bytes."
     ]
    }
   ],
   "source": [
    "# Initialize the tokenizer and model\n",
    "e5_tokenizer = AutoTokenizer.from_pretrained('intfloat/e5-base-v2')\n",
    "e5_model = AutoModel.from_pretrained('intfloat/e5-base-v2')\n",
    "\n",
    "def average_pool(last_hidden_states, attention_mask):\n",
    "    \"\"\"\n",
    "    Applies average pooling to the last hidden states of the model.\n",
    "    Args:\n",
    "        last_hidden_states (Tensor): The output from the model containing hidden states.\n",
    "        attention_mask (Tensor): The attention mask to identify real tokens.\n",
    "    Returns:\n",
    "        Tensor: The average pooled embeddings.\n",
    "    \"\"\"\n",
    "    last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
    "    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
    "\n",
    "def get_e5(text):\n",
    "    \"\"\"\n",
    "    Generates the embeddings for a single text input (query or passage).\n",
    "    Args:\n",
    "        text (str or list): Input text or list of texts.\n",
    "    Returns:\n",
    "        Tensor: Normalized embeddings.\n",
    "    \"\"\"\n",
    "    inputs = e5_tokenizer(text, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = e5_model(**inputs)\n",
    "    \n",
    "    # Apply average pooling\n",
    "    embeddings = average_pool(outputs.last_hidden_state, inputs['attention_mask'])\n",
    "    \n",
    "    # Normalize embeddings\n",
    "    return F.normalize(embeddings, p=2, dim=1)\n",
    "\n",
    "e5_embeddings = get_e5(unique_articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2837465-5229-4bfd-93c1-a7cd1d9b8f24",
   "metadata": {},
   "source": [
    "## Ensembling Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5cd35071-ef06-425f-a43a-6c2645c47f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_embedding_dict = {\n",
    "    \"TF-IDF\": tfidf_matrix,\n",
    "    \"bert-base-uncased\": bert_embeddings,\n",
    "    \"gte-base-en-v1.5\": gte_embeddings,\n",
    "    \"bge-large-zh-v1.5\": bge_embeddings\n",
    "    # \"e5-base-v2\": e5_embeddings\n",
    "}\n",
    "\n",
    "def cosine_similiarity_search(query_embedding, article_embeddings, unique_articles):\n",
    "    # Compute cosine similarity between the query and all articles\n",
    "    similarities = cosine_similarity(query_embedding, article_embeddings).flatten()\n",
    "    \n",
    "    # Get the indices of the top 5 most similar articles\n",
    "    top_indices = np.argsort(similarities)[-5:][::-1]\n",
    "    \n",
    "    # Create a DataFrame to hold the results\n",
    "    results_df = pd.DataFrame({\n",
    "        'Article': np.array(unique_articles)[top_indices],\n",
    "        'Similarity Score': similarities[top_indices]\n",
    "    })\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "def input_output_pipeline(query_embedding_dict, embedding_dict, all_articles):\n",
    "    output_df = pd.DataFrame(columns=[\"model\", \"similarity_score\", \"article\"])\n",
    "    \n",
    "    for model in tqdm(query_embedding_dict.keys()):\n",
    "        similarity_df = cosine_similiarity_search(\n",
    "                            query_embedding_dict[model],\n",
    "                            article_embedding_dict[model],\n",
    "                            all_articles\n",
    "                        )\n",
    "        \n",
    "        best_row = pd.DataFrame({\n",
    "                        \"model\": [model],\n",
    "                        \"similarity_score\": [similarity_df[\"Similarity Score\"].iloc[0]],\n",
    "                        \"article\": [similarity_df[\"Article\"].iloc[0]]\n",
    "                    })\n",
    "        \n",
    "        output_df = pd.concat([output_df, best_row])\n",
    "        \n",
    "    if output_df['article'].value_counts().max() > 1:\n",
    "        return output_df['article'].value_counts().idxmax()\n",
    "    else:\n",
    "        # Find the highest similarity score\n",
    "        highest_score = max(output[\"similarity_score\"])\n",
    "        \n",
    "        # Get the article with the highest similarity score\n",
    "        return output[output[\"similarity_score\"] == highest_score].iloc[0][\"article\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5e72e5-6f99-4615-94fc-29e7cd007264",
   "metadata": {},
   "source": [
    "## Validating on \"London meeting of finance ministers and central bankers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7410d0b9-74df-4aa1-a223-cdc33f1e1c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 18.89it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'tsunami debt deal to be announced chancellor gordon brown has said he hopes to announce a deal to suspend debt interest repayments by tsunamihit nations later on friday the agreement by the g8 group of wealthy nations would save affected countries £3bn pounds a year he said the deal is thought to have been hammered out on thursday night after japan one of the biggest creditor nations finally signed up to it mr brown first proposed the idea earlier this week g8 ministers are also believed to have agreed to instruct the world bank and the international monetary fund to complete a country by country analysis of the reconstruction problems faced by all states hit by the disaster mr brown has been locked in talks with finance ministers of the g8 which britain now chairs germany also proposed a freeze and canada has begun its own moratorium the expected deal comes as foreign secretary jack straw said the number of britons dead or missing in the disaster have reached 440'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example search query\n",
    "query = \"London meeting of finance ministers and central bankers\"\n",
    "\n",
    "query_embedding_dict = {\n",
    "    \"TF-IDF\": get_tfidf(query),\n",
    "    \"bert-base-uncased\": [get_bert(query)],\n",
    "    \"gte-base-en-v1.5\": [get_gte(query)],\n",
    "    \"bge-large-zh-v1.5\": get_bge([query]),\n",
    "    # \"e5-base-v2\": get_e5(query)\n",
    "}\n",
    "\n",
    "output = input_output_pipeline(query_embedding_dict, article_embedding_dict, unique_articles)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6428dda6-634d-4a19-8989-06ed5c980f1d",
   "metadata": {},
   "source": [
    "## Validating on \"Amit Yoran leaves the Department of# Example search query\n",
    "query = \"Amit Yoran leaves the Department of Homeland Security\" Homeland Security\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "925954d1-0360-4acb-9932-a022deeccfc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 19.12it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'us cyber security chief resigns the man making sure us computer networks are safe and secure has resigned after only a year in his post amit yoran was director of the national cyber security division within the us department of homeland security created following the 911 attacks the division was tasked with improving us defences against malicious hackers viruses and other netbased threats reports suggest he left because his division was not given enough clout within the larger organisation mr yoran took up his post in september 2003 and his first task was to get the cyber security division up and running the organisation had a staff of about 60 people and a budget of about 80m £4454m the division was charged with thinking up and carrying out action to make us networks more impervious to attack and disruption by the viruses worms and hack attacks that have become commonplace in the last 12 months mr yoran oversaw the creation of a cyber alert system that sends out warnings about big hitting viruses and net attacks as they occur the warnings also contained information about how firms and organisations could protect themselves against these attacks the cyber security division also audited us government networks to discover exactly what was sitting on which network the next step was to be the creation of a scanning system to identify vulnerabilities that made federal networks and machines susceptible to attack by malicious hackers and virus writers mr yorans division was also doing work to identify the networks and machines that had been broken into by cyber criminals despite this success mr yoran left his post abruptly at the end of last week reportedly only giving one days notice to bosses at the department of homeland security amit yoran has been a valuable contributor on cyber security issues over the past year and we appreciate his efforts in starting the departments cybersecurity program said a department of homeland security spokeswoman some reports have suggested that mr yoran felt frustrated by the lack of prominence given to work to protect against netbased threats in the wider homeland organisation an attempt by us politicians to pass a law to promote mr yoran and raise the profile of his departments work is now mired in congress'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example search query\n",
    "query = \"Amit Yoran leaves the Department of Homeland Security\"\n",
    "\n",
    "query_embedding_dict = {\n",
    "    \"TF-IDF\": get_tfidf(query),\n",
    "    \"bert-base-uncased\": [get_bert(query)],\n",
    "    \"gte-base-en-v1.5\": [get_gte(query)],\n",
    "    \"bge-large-zh-v1.5\": get_bge([query]),\n",
    "    # \"e5-base-v2\": get_e5(query)\n",
    "}\n",
    "\n",
    "output = input_output_pipeline(query_embedding_dict, article_embedding_dict, unique_articles)\n",
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda-gpt",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
